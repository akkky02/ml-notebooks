{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-LMcXIAA35z"
   },
   "source": [
    "# Notes XGBoost Tuning\n",
    "- **1999 Gradient Boosting paper (https://jerryfriedman.su.domains/ftp/trebst.pdf)**\n",
    "  - set a large value for the number of trees, then tune learning rate (shrinkage). These are inversely related.\n",
    "    -  small values of learning rate (<=0.1) gives better generalization error. \n",
    "    - a number of trees in the range 100 to 500 \n",
    "  - the number of terminal nodes in a tree between 2 and 8\n",
    "  - all subsampling percentages are better than deterministic boosting.  30% to 50% Or  50% to 80% depending on problem\n",
    "\n",
    "- **Chapter 10 titled Boosting and Additive Trees of the book The Elements of Statistical Learning: Data Mining, Inference, and Prediction**\n",
    "\n",
    "  - good value for the number of nodes in the tree : 4 to 8\n",
    "  - Early stopping with validation dataset.\n",
    "\n",
    "- **Sklearn default values** \n",
    "  - learning rate = 0.1 (shrinkage)\n",
    "\n",
    "  - number of  estimators = 100 (number of trees). \n",
    "  - max_depth = 3\n",
    "  - min_samples_split =2\n",
    "  - min_samples_leaf = 1\n",
    "  - subsample = 1\n",
    "\n",
    "- **Abhisek Thakur Linkeding Post**\n",
    "https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur\n",
    "\n",
    "\n",
    " <img src =\"https://drive.google.com/uc?export=view&id=1R9Zq1BV8TGLlLxXu9kh122tp38KkeXJI\" width = 700 >\n",
    "\n",
    " -Typically we do not need to change default values of Gamma, Aplpha, Lambda\n",
    "\n",
    "\n",
    "- **Owen Zhang’s talk** (https://www.youtube.com/watch?v=LgLcfZjNF44)\n",
    "\n",
    "  - Number of Trees :  fixed value between 100 and 1000 \n",
    "\n",
    "  - Learning Rate simplified to the ratio: [2 to 10]/ NUmber of trees.\n",
    "\n",
    "  - Row Sampling (subsample) range : [0.5, 0.75, 1.0]\n",
    "\n",
    "  - Column Sampling (colsample bytree and maybe colsample_bylevel) range : [0.4, 0.6, 0.8, 1.0].\n",
    "\n",
    "  - Tree Size (max_depth)Range: [4, 6, 8, 10]\n",
    "\n",
    "  - Min_child_weight = 3/(Percentage of Rare Events)\n",
    "\n",
    "  - Min Split Gain (gamma) fixed with a value of zero.\n",
    "\n",
    "  - Do not optimize reg_alpha and reg_lambda\n",
    "\n",
    "- **Medium Article**\n",
    "https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
    "\n",
    "  - max_depth: 3–10\n",
    "  - n_estimators: 100 (lots of observations) to 1000 (few observations)\n",
    "  - learning_rate: 0.01 – 0.3\n",
    "  - colsample_bytree (or bylevel) : 0.5–1\n",
    "  - subsample: 0.6–1\n",
    "  \n",
    "\n",
    "- XGBoost can also handle missing values - set missing  values to zero.\n",
    "- For imbalanced datasets use class_weights.\n",
    "\n",
    "Summary: The various recommendatons are very similar except for gamma, reg_alpha and reg_lambda.\n",
    "Some fine tune and some do not fine tune these parameters.\n",
    "\n",
    "**Sequential GridSearch Approach (with Early Stopping)**\n",
    "\n",
    "Approach1 : Use native xgboost.cv. \n",
    "\n",
    "- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "- https://github.com/druce/iowa/blob/master/hyperparameter_optimization.ipynb\n",
    "- https://stackoverflow.com/questions/42993550/gridsearchcv-xgboost-early-stopping\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "xgboost_tips.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
