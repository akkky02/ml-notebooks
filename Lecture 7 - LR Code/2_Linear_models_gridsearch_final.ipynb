{"cells":[{"cell_type":"markdown","metadata":{"id":"D2XQ5WdK4g6d"},"source":["# Linear Regression with Normal Equation"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-09T16:36:12.455562Z","start_time":"2020-03-09T16:36:07.052609Z"},"id":"6fXQ6wG94g6f"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from math import sqrt"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-09T16:36:14.899167Z","start_time":"2020-03-09T16:36:12.482623Z"},"id":"8C996IeZ4g6s"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.preprocessing  import PolynomialFeatures\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import ElasticNet\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.datasets import load_boston"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665247541629,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"u_auPgp3IzLt","outputId":"3d751a41-020c-4c91-c385-d2e92293d0d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["train mse: 19.640519427908043\n","train rmse: 4.431762564477935\n","train r2: 0.7697699488741149\n","\n","test mse: 29.78224509230241\n","test rmse: 5.457311159564059\n","test r2: 0.6354638433202123\n","regression co-efficients : [-10.47489456   4.40174969  -0.15735494   2.39341594  -7.57645867\n","  19.67024242  -0.68311581 -15.71607313   5.52186497  -5.91977522\n","  -9.26413928   3.34889385 -17.59386711]\n","\n"," intercept 27.492727907952286\n","[0.76260062 0.56956022 0.77935231 0.70774465 0.79031905]\n","0.721915369370549\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["data = load_boston()\n","\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","# split into training and test data set \n","X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n","\n","# create pipeline\n","reg_norm_pipe = Pipeline([\n","\n","    # feature Scaling\n","    ('scaler', MinMaxScaler()),\n","    # regression\n","    ('norm_reg', LinearRegression())\n","])\n","\n","# let's fit the pipeline\n","reg_norm_pipe.fit(X_train, y_train)\n","\n","# let's get the predictions\n","X_train_preds = reg_norm_pipe.predict(X_train)\n","X_test_preds = reg_norm_pipe.predict(X_test)\n","\n","# check model performance:\n","\n","print(f'train mse: {mean_squared_error(y_train, X_train_preds)}')\n","print(f'train rmse: {sqrt(mean_squared_error(y_train, X_train_preds))}')\n","print(f'train r2: {r2_score(y_train, X_train_preds)}')\n","print()\n","print(f'test mse: {mean_squared_error(y_test, X_test_preds)}')\n","print(f'test rmse: {sqrt(mean_squared_error(y_test, X_test_preds))}')\n","print(f'test r2: {r2_score(y_test, X_test_preds)}')\n","\n","# print regression co-effeicient \n","print('regression co-efficients :',reg_norm_pipe.named_steps['norm_reg'].coef_)\n","print('\\n intercept',reg_norm_pipe.named_steps['norm_reg'].intercept_)\n","\n","scores = cross_val_score(reg_norm_pipe, X_train, y_train,cv=5)\n","print(scores)\n","print(scores.mean())"]},{"cell_type":"markdown","metadata":{"id":"LYVi94JS4g8Z"},"source":["# Linear Regression Stochastic Gradient Descent with Scikit Learn with GridSerach"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:10:53.116395Z","start_time":"2020-03-08T20:10:53.095332Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1548,"status":"ok","timestamp":1665247543174,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Oc5GTQW74g88","outputId":"03e4da1b-462e-405b-ee7f-b636bcd6037e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["train mse: 21.159373060735554\n","train rmse: 4.599931853923007\n","train r2: 0.7519656463544101\n","\n","test mse: 32.38357507121193\n","test rmse: 5.6906568224776946\n","test r2: 0.6036234353916414\n","Best parameters: {'sgd_reg__eta0': 0.05}\n","Best cross-validation score: -3.21\n","Best estimator:\n","Pipeline(steps=[('scaler', MinMaxScaler()),\n","                ('sgd_reg',\n","                 SGDRegressor(eta0=0.05, max_iter=10000, tol=1e-06))])\n"]}],"source":["data = load_boston()\n","\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","# split into training and test data set \n","X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n","\n","# create pipeline\n","reg_sgd_pipe = Pipeline([\n","\n","    # feature Scaling\n","    ('scaler', MinMaxScaler()),\n","    # regression\n","    ('sgd_reg', SGDRegressor(max_iter=10000, tol = 1e-6))\n","])\n","\n","param_sgd = {'sgd_reg__eta0':[0.01, 0.05, 0.1 ,0.5]}\n","grid_sgd = GridSearchCV(reg_sgd_pipe, param_sgd,cv=5, n_jobs=-1, return_train_score = True,scoring ='neg_mean_absolute_error')\n","\n","# let's fit the pipeline\n","grid_sgd.fit(X_train, y_train)\n","\n","# let's get the predictions\n","X_train_preds = grid_sgd.predict(X_train)\n","X_test_preds = grid_sgd.predict(X_test)\n","\n","# check model performance:\n","\n","print(f'train mse: {mean_squared_error(y_train, X_train_preds)}')\n","print(f'train rmse: {sqrt(mean_squared_error(y_train, X_train_preds))}')\n","print(f'train r2: {r2_score(y_train, X_train_preds)}')\n","print()\n","print(f'test mse: {mean_squared_error(y_test, X_test_preds)}')\n","print(f'test rmse: {sqrt(mean_squared_error(y_test, X_test_preds))}')\n","print(f'test r2: {r2_score(y_test, X_test_preds)}')\n","\n","print(\"Best parameters: {}\".format(grid_sgd.best_params_))\n","print(\"Best cross-validation score: {:.2f}\".format(grid_sgd.best_score_))\n","\n","print(\"Best estimator:\\n{}\".format(grid_sgd.best_estimator_))"]},{"cell_type":"markdown","metadata":{"id":"98UQDqoF4g9r"},"source":["##  SGD with regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:10:56.186590Z","start_time":"2020-03-08T20:10:56.162023Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1719,"status":"ok","timestamp":1665247544891,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"FXRgjAT64g9r","outputId":"dcf3ba84-7982-4a24-b9ab-b8126dd633af"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["train mse: 22.621585066839636\n","train rmse: 4.756215414259497\n","train r2: 0.7348253081796532\n","\n","test mse: 35.02931215908023\n","test rmse: 5.918556594228041\n","test r2: 0.5712394822474924\n","Best parameters: {'sgd_reg__alpha': 0.01, 'sgd_reg__eta0': 0.5, 'sgd_reg__penalty': 'l1'}\n","Best cross-validation score: 0.72\n","Best estimator:\n","Pipeline(steps=[('scaler', MinMaxScaler()),\n","                ('sgd_reg',\n","                 SGDRegressor(alpha=0.01, eta0=0.5, max_iter=10000,\n","                              penalty='l1', tol=1e-06))])\n"]}],"source":["data = load_boston()\n","\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","# split into training and test data set \n","X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n","\n","# create pipeline\n","reg_sgd_pipe = Pipeline([\n","\n","    # feature Scaling\n","    ('scaler', MinMaxScaler()),\n","    # regression\n","    ('sgd_reg', SGDRegressor(max_iter=10000, tol = 1e-6))\n","])\n","\n","param_sgd = {'sgd_reg__eta0':[0.01, 0.05, 0.1 ,0.5], 'sgd_reg__penalty' :['l1','l2'],'sgd_reg__alpha' :[0.1,0.01,0.001] }\n","grid_sgd = GridSearchCV(reg_sgd_pipe, param_sgd,cv=5, n_jobs=-1, return_train_score = True)\n","\n","# let's fit the pipeline\n","grid_sgd.fit(X_train, y_train)\n","\n","# let's get the predictions\n","X_train_preds = grid_sgd.predict(X_train)\n","X_test_preds = grid_sgd.predict(X_test)\n","\n","# check model performance:\n","\n","print(f'train mse: {mean_squared_error(y_train, X_train_preds)}')\n","print(f'train rmse: {sqrt(mean_squared_error(y_train, X_train_preds))}')\n","print(f'train r2: {r2_score(y_train, X_train_preds)}')\n","print()\n","print(f'test mse: {mean_squared_error(y_test, X_test_preds)}')\n","print(f'test rmse: {sqrt(mean_squared_error(y_test, X_test_preds))}')\n","print(f'test r2: {r2_score(y_test, X_test_preds)}')\n","\n","print(\"Best parameters: {}\".format(grid_sgd.best_params_))\n","print(\"Best cross-validation score: {:.2f}\".format(grid_sgd.best_score_))\n","\n","print(\"Best estimator:\\n{}\".format(grid_sgd.best_estimator_))"]},{"cell_type":"markdown","metadata":{"id":"6dzxyyNm4g-W"},"source":["# Polynomial Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:10:57.210740Z","start_time":"2020-03-08T20:10:57.183604Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1665247545121,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"P0TdWdWO4g-W","outputId":"da5f342e-1482-46ac-d0cd-815755456e15"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["train mse: 19.640519427908043\n","train rmse: 4.431762564477935\n","train r2: 0.7697699488741149\n","\n","test mse: 29.78224509230243\n","test rmse: 5.45731115956406\n","test r2: 0.6354638433202121\n","Best parameters:  {'polynomialfeatures__degree': 1}\n","Best cross-validation score: 0.72\n","Poly features:  14\n","Coefficients:  [  0.         -10.47489456   4.40174969  -0.15735494   2.39341594\n","  -7.57645867  19.67024242  -0.68311581 -15.71607313   5.52186497\n","  -5.91977522  -9.26413928   3.34889385 -17.59386711]\n"]}],"source":["data = load_boston()\n","\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","# split into training and test data set \n","X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n","\n","#apply polynomial regression in pipeline\n","#pipe_poly = make_pipeline(PolynomialFeatures(),MinMaxScaler(), LinearRegression())\n","pipe_poly=Pipeline([ \n","    ('polynomialfeatures', PolynomialFeatures()),\n","    ('scaler',MinMaxScaler()),\n","    ('norm_reg', LinearRegression())\n","    \n","])\n","#define a list of parameters\n","param_poly = {'polynomialfeatures__degree':range(1,5)}\n","\n","grid_poly = GridSearchCV(pipe_poly, param_poly,cv=5, n_jobs=-1, return_train_score = True)\n","\n","\n","grid_poly.fit(X_train, y_train)\n","\n","# let's get the predictions\n","X_train_preds = grid_poly.predict(X_train)\n","X_test_preds = grid_poly.predict(X_test)\n","\n","# check model performance:\n","\n","print(f'train mse: {mean_squared_error(y_train, X_train_preds)}')\n","print(f'train rmse: {sqrt(mean_squared_error(y_train, X_train_preds))}')\n","print(f'train r2: {r2_score(y_train, X_train_preds)}')\n","print()\n","print(f'test mse: {mean_squared_error(y_test, X_test_preds)}')\n","print(f'test rmse: {sqrt(mean_squared_error(y_test, X_test_preds))}')\n","print(f'test r2: {r2_score(y_test, X_test_preds)}')\n","\n","#find best parameters\n","print('Best parameters: ', grid_poly.best_params_)\n","\n","print(\"Best cross-validation score: {:.2f}\".format(grid_poly.best_score_))\n","\n","# print the coefficients\n","print('Poly features: ', grid_poly.best_estimator_.named_steps['polynomialfeatures'].n_output_features_)\n","print('Coefficients: ', grid_poly.best_estimator_.named_steps['norm_reg'].coef_)"]},{"cell_type":"markdown","metadata":{"id":"ZgdP9bXr4g-t"},"source":["# Ridge Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:10:57.806319Z","start_time":"2020-03-08T20:10:57.772222Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665247545122,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"8MGw-xR44g-u","outputId":"f7e721fc-ce8b-4ffc-b9a0-df5ccc61dd44"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training set score:  0.7656443349364728\n","Test set score:  0.6214583227921031\n","best parameters: {'ridge__alpha': 1}\n","Best cross-validation score: 0.7244032269386581\n"]}],"source":["data = load_boston()\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","ridge_pipe = Pipeline([\n","\n","    # feature Scaling\n","    ('scaler', MinMaxScaler()),\n","    # regression\n","    ('ridge', Ridge())\n","])\n","\n","#define a list of parameters\n","param_ridge = {'ridge__alpha':[0.001, 0.01, 0.1, 1, 10, 100] }\n","\n","grid_ridge = GridSearchCV(ridge_pipe, param_ridge, cv=5, return_train_score = True)\n","grid_ridge.fit(X_train, y_train)\n","\n","grid_ridge_train_score = grid_ridge.score(X_train, y_train)\n","grid_ridge_test_score = grid_ridge.score(X_test, y_test)\n","\n","print('Training set score: ', grid_ridge_train_score)\n","print('Test set score: ', grid_ridge_test_score)\n","\n","#find best parameters\n","print('best parameters:',grid_ridge.best_params_)\n","print('Best cross-validation score:', grid_ridge.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"PB12qKH94g-2"},"source":["# Lasso Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:10:58.237896Z","start_time":"2020-03-08T20:10:58.012282Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1665247545489,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"eiVIxV314g-4","outputId":"8fe0d01b-4fbd-4708-ffcd-386466c80b96"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training set score:  0.7687862301878807\n","Test score:  0.6310389471799465\n","Best parameters:  {'lasso__alpha': 0.01}\n","Best cross-validation score: 0.7230563618131272\n"]}],"source":["data = load_boston()\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","lasso_pipe = Pipeline([\n","\n","    # feature Scaling\n","    ('scaler', MinMaxScaler()),\n","    # regression\n","    ('lasso', Lasso(max_iter=1000, tol = 1e-5))\n","])\n","\n","#define a list of parameters\n","param_lasso = {'lasso__alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10] }\n","\n","grid_lasso = GridSearchCV(lasso_pipe, param_lasso, cv=5, return_train_score = True)\n","grid_lasso.fit(X_train, y_train)\n","\n","grid_lasso_train_score = grid_lasso.score(X_train, y_train)\n","grid_lasso_test_score = grid_lasso.score(X_test, y_test)\n","\n","print('Training set score: ', grid_lasso_train_score)\n","print('Test score: ', grid_lasso_test_score)\n","\n","#find best parameters\n","print('Best parameters: ', grid_lasso.best_params_)\n","print('Best cross-validation score:', grid_lasso.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"1_mj-oxz4g-9"},"source":["# ElasticNet "]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:10:58.992531Z","start_time":"2020-03-08T20:10:58.253938Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":988,"status":"ok","timestamp":1665247546476,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"xmbqQGqB4g_A","outputId":"84452012-4d14-4478-ccc1-e8b634501552"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training set score:  0.7650885772611327\n","Test score:  0.6204728438000011\n","Best parameters:  {'elastic__alpha': 0.01, 'elastic__l1_ratio': 0.8}\n","Best cross-validation score: 0.7239800576089702\n"]}],"source":["data = load_boston()\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","elasticnet = Pipeline([\n","\n","    # feature Scaling\n","    ('scaler', MinMaxScaler()),\n","    # regression\n","    ('elastic', ElasticNet())\n","])\n","\n","#define a list of parameters\n","param_elasticnet = {'elastic__alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10], 'elastic__l1_ratio' :[0.2,0.4,0.6,0.8]}\n","\n","grid_elasticnet = GridSearchCV(elasticnet , param_elasticnet, cv=5, return_train_score = True)\n","grid_elasticnet.fit(X_train, y_train)\n","\n","grid_elasticnet_train_score = grid_elasticnet.score(X_train, y_train)\n","grid_elasticnet_test_score = grid_elasticnet.score(X_test, y_test)\n","\n","print('Training set score: ', grid_elasticnet_train_score)\n","print('Test score: ', grid_elasticnet_test_score)\n","\n","#find best parameters\n","print('Best parameters: ', grid_elasticnet.best_params_)\n","print('Best cross-validation score:', grid_elasticnet.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"PIy7Fpe34g_P"},"source":["# Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:00.516509Z","start_time":"2020-03-08T20:11:00.493946Z"},"id":"pm6DE8Zi4g_P"},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer\n","data = load_breast_cancer()\n","\n","X = pd.DataFrame(data.data, columns=data.feature_names)\n","y = data.target"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:00.555611Z","start_time":"2020-03-08T20:11:00.530545Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":974,"status":"ok","timestamp":1665247547449,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"RphVRGfL4g_T","outputId":"9fb2506f-5568-40f4-9a5f-383c0c7e4deb"},"outputs":[{"output_type":"stream","name":"stdout","text":["train score:  0.9824175824175824\n","test score:  0.9649122807017544\n","Best parameters:  {'logreg__C': 10}\n","Best cross-validation score: 0.9802197802197803\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n","\n","scaler = MinMaxScaler()\n","pipe_logreg=Pipeline([ \n","    ('scaler',MinMaxScaler()),\n","    ('logreg', LogisticRegression(max_iter=1000))\n","    \n","])\n","# define a list of parameters\n","\n","param_logreg = {'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n","\n","#apply grid search\n","grid_logreg = GridSearchCV(pipe_logreg, param_logreg, cv=5, return_train_score=True)\n","grid_logreg.fit(X_train, y_train)\n","\n","print('train score: ', grid_logreg.score(X_train, y_train))\n","print('test score: ', grid_logreg.score(X_test, y_test))\n","\n","#find best parameters\n","print('Best parameters: ', grid_logreg.best_params_)\n","print('Best cross-validation score:', grid_logreg.best_score_)\n"]},{"cell_type":"markdown","metadata":{"id":"PhfwAmhb4g_z"},"source":["# Softmax Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:13.100237Z","start_time":"2020-03-08T20:11:13.079181Z"},"id":"Xq79T3nG4g_z"},"outputs":[],"source":["from sklearn.datasets import load_iris\n","\n","iris = load_iris()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:13.106252Z","start_time":"2020-03-08T20:11:13.102240Z"},"id":"oa9F_acR4g_1"},"outputs":[],"source":["X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n","y = iris[\"target\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:13.147373Z","start_time":"2020-03-08T20:11:13.108257Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665247547450,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"iZU800nn4g_3","outputId":"41206318-1672-4bed-b7d1-2f16dafe92ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=10, multi_class='multinomial')"]},"metadata":{},"execution_count":15}],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n","\n","softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10)\n","softmax_reg.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:13.167425Z","start_time":"2020-03-08T20:11:13.149378Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665247547450,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Z1tsY0xw4g_6","outputId":"05d4a7a3-5559-4bf5-e04e-6e4cd8720bb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train score: 0.9643\n","Test score: 0.9737\n"]}],"source":["print('Train score: {:.4f}'.format(softmax_reg.score(X_train, y_train)))\n","print('Test score: {:.4f}'.format(softmax_reg.score(X_test, y_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:13.191490Z","start_time":"2020-03-08T20:11:13.169431Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665247547450,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"Hde3teGS4g_9","outputId":"cbf076fb-33af-4c36-dac3-a44dfce70fe6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":17}],"source":["softmax_reg.predict([[5, 2]])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-03-08T20:11:13.229094Z","start_time":"2020-03-08T20:11:13.193495Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665247547450,"user":{"displayName":"Shaannoor Mann","userId":"02520257695567980696"},"user_tz":300},"id":"mGy6CuLi4hAA","outputId":"3ad41c29-8c74-4382-f2cd-c33ad3287283"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.33384149e-06, 7.90876321e-02, 9.20911034e-01]])"]},"metadata":{},"execution_count":18}],"source":["softmax_reg.predict_proba([[5, 2]])"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"pt10","language":"python","name":"pt10"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}